{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal = pd.read_csv('ptbdb_normal.csv', header=None)\n",
    "df_abnormal = pd.read_csv('ptbdb_abnormal.csv', header=None)\n",
    "\n",
    "# Split into train, validation, test\n",
    "df_normal_train = df_normal[:int(0.8*len(df_normal))]\n",
    "df_normal_test = df_normal[int(0.8*len(df_normal)):]\n",
    "\n",
    "df_abnormal_train = df_abnormal[:int(0.8*len(df_abnormal))]\n",
    "df_abnormal_test = df_abnormal[int(0.8*len(df_abnormal)):]\n",
    "\n",
    "# Add normal and abnormal data together\n",
    "df_train = pd.concat([df_normal_train, df_abnormal_train])\n",
    "df_test = pd.concat([df_normal_test, df_abnormal_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900324</td>\n",
       "      <td>0.358590</td>\n",
       "      <td>0.051459</td>\n",
       "      <td>0.046596</td>\n",
       "      <td>0.126823</td>\n",
       "      <td>0.133306</td>\n",
       "      <td>0.119125</td>\n",
       "      <td>0.110616</td>\n",
       "      <td>0.113047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.794681</td>\n",
       "      <td>0.375387</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171923</td>\n",
       "      <td>0.283859</td>\n",
       "      <td>0.293754</td>\n",
       "      <td>0.325912</td>\n",
       "      <td>0.345083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.909029</td>\n",
       "      <td>0.791482</td>\n",
       "      <td>0.423169</td>\n",
       "      <td>0.186712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007836</td>\n",
       "      <td>0.063032</td>\n",
       "      <td>0.077002</td>\n",
       "      <td>0.074957</td>\n",
       "      <td>0.077342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.478893</td>\n",
       "      <td>0.056760</td>\n",
       "      <td>0.064176</td>\n",
       "      <td>0.081289</td>\n",
       "      <td>0.072732</td>\n",
       "      <td>0.055619</td>\n",
       "      <td>0.048774</td>\n",
       "      <td>0.054478</td>\n",
       "      <td>0.041643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867238</td>\n",
       "      <td>0.201360</td>\n",
       "      <td>0.099349</td>\n",
       "      <td>0.141336</td>\n",
       "      <td>0.120934</td>\n",
       "      <td>0.108516</td>\n",
       "      <td>0.096393</td>\n",
       "      <td>0.093436</td>\n",
       "      <td>0.100828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  1.000000  0.900324  0.358590  0.051459  0.046596  0.126823  0.133306   \n",
       "1  1.000000  0.794681  0.375387  0.116883  0.000000  0.171923  0.283859   \n",
       "2  0.909029  0.791482  0.423169  0.186712  0.000000  0.007836  0.063032   \n",
       "3  1.000000  0.478893  0.056760  0.064176  0.081289  0.072732  0.055619   \n",
       "4  1.000000  0.867238  0.201360  0.099349  0.141336  0.120934  0.108516   \n",
       "\n",
       "        7         8         9    ...  178  179  180  181  182  183  184  185  \\\n",
       "0  0.119125  0.110616  0.113047  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.293754  0.325912  0.345083  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.077002  0.074957  0.077342  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.048774  0.054478  0.041643  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.096393  0.093436  0.100828  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   186  187  \n",
       "0  0.0  0.0  \n",
       "1  0.0  0.0  \n",
       "2  0.0  0.0  \n",
       "3  0.0  0.0  \n",
       "4  0.0  0.0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ECG1DCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECG1DCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size=5, stride=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, stride=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 43, 256)  # Adjust the first dimension based on the output of the last MaxPool1d layer\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.fc3 = nn.Linear(64, 2)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)  # Flatten the tensor\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu5(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch 1/20\n",
      "----------\n",
      "epoch train loss: 0.0125 Acc: 80.7388\n",
      "Epoch 2/20\n",
      "----------\n",
      "epoch train loss: 0.0084 Acc: 88.4278\n",
      "Epoch 3/20\n",
      "----------\n",
      "epoch train loss: 0.0055 Acc: 92.7835\n",
      "Epoch 4/20\n",
      "----------\n",
      "epoch train loss: 0.0040 Acc: 95.3436\n",
      "Epoch 5/20\n",
      "----------\n",
      "epoch train loss: 0.0030 Acc: 96.5292\n",
      "Epoch 6/20\n",
      "----------\n",
      "epoch train loss: 0.0022 Acc: 97.4399\n",
      "Epoch 7/20\n",
      "----------\n",
      "epoch train loss: 0.0017 Acc: 98.0584\n",
      "Epoch 8/20\n",
      "----------\n",
      "epoch train loss: 0.0014 Acc: 98.4021\n",
      "Epoch 9/20\n",
      "----------\n",
      "epoch train loss: 0.0014 Acc: 98.4622\n",
      "Epoch 10/20\n",
      "----------\n",
      "epoch train loss: 0.0008 Acc: 99.1237\n",
      "Epoch 11/20\n",
      "----------\n",
      "epoch train loss: 0.0007 Acc: 99.1065\n",
      "Epoch 12/20\n",
      "----------\n",
      "epoch train loss: 0.0009 Acc: 98.8918\n",
      "Epoch 13/20\n",
      "----------\n",
      "epoch train loss: 0.0005 Acc: 99.3900\n",
      "Epoch 14/20\n",
      "----------\n",
      "epoch train loss: 0.0003 Acc: 99.6478\n",
      "Epoch 15/20\n",
      "----------\n",
      "epoch train loss: 0.0005 Acc: 99.3814\n",
      "Epoch 16/20\n",
      "----------\n",
      "epoch train loss: 0.0004 Acc: 99.6134\n",
      "Epoch 17/20\n",
      "----------\n",
      "epoch train loss: 0.0004 Acc: 99.5619\n",
      "Epoch 18/20\n",
      "----------\n",
      "epoch train loss: 0.0006 Acc: 99.4759\n",
      "Epoch 19/20\n",
      "----------\n",
      "epoch train loss: 0.0003 Acc: 99.7594\n",
      "Epoch 20/20\n",
      "----------\n",
      "epoch train loss: 0.0003 Acc: 99.5962\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import optim\n",
    "\n",
    "# Convert dataframes to tensors\n",
    "X_train = torch.tensor(df_train.iloc[:, :-1].values, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "y_train = torch.tensor(df_train.iloc[:, -1].values, dtype=torch.long)\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = ECG1DCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "EPOCHS_NO = 20\n",
    "# Training loop\n",
    "best_model_wts = model.state_dict()\n",
    "best_acc = 0.0\n",
    "iteration = 0\n",
    "for epoch in range(EPOCHS_NO):  # Number of epochs\n",
    "    print('Epoch {}/{}'.format(epoch+1, EPOCHS_NO))\n",
    "    print('-'*10)\n",
    "    train_loss = 0.0\n",
    "    train_corrects = 0.0\n",
    "    model = model.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iter_loss = loss.item()\n",
    "        train_loss += iter_loss\n",
    "        iter_corrects = torch.sum(preds == labels.data).to(torch.float32)\n",
    "        train_corrects += iter_corrects\n",
    "        iteration += 1\n",
    "    epoch_loss = train_loss / len(train_dataset)\n",
    "    epoch_acc = train_corrects / len(train_dataset)\n",
    "    epoch_acc = epoch_acc * 100\n",
    "\n",
    "    if epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model_wts = model.state_dict()\n",
    "\n",
    "    print('epoch train loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that `model` is your model\n",
    "model.load_state_dict(best_model_wts)\n",
    "\n",
    "# Convert dataframes to tensors\n",
    "X_test = torch.tensor(df_test.iloc[:, :-1].values, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "y_test = torch.tensor(df_test.iloc[:, -1].values, dtype=torch.long)\n",
    "\n",
    "# Create dataloaders\n",
    "test_dataset = TensorDataset(X_train, y_train)\n",
    "test_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Then you can evaluate the model\n",
    "model.eval()\n",
    "\n",
    "test_dataset_size = len(test_dataset)\n",
    "true_positive = 0\n",
    "true_negative = 0\n",
    "false_positive = 0\n",
    "false_negative = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        true_positive += (predicted * labels).sum().item()\n",
    "        true_negative += ((1 - predicted) * (1 - labels)).sum().item()\n",
    "        false_positive += (predicted * (1 - labels)).sum().item()\n",
    "        false_negative += ((1 - predicted) * labels).sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.9993\n",
      "Precision: 0.9994\n",
      "Recall: 0.9996\n",
      "F1 Score: 0.9995\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "acc = (true_positive + true_negative) / test_dataset_size\n",
    "print('Test Acc: {:.4f}'.format(acc))\n",
    "\n",
    "# Precision\n",
    "prec = true_positive / (true_positive + false_positive)\n",
    "print('Precision: {:.4f}'.format(prec))\n",
    "# Recall\n",
    "rec = true_positive / (true_positive + false_negative)\n",
    "print('Recall: {:.4f}'.format(rec))\n",
    "# F1 Score\n",
    "f1 = 2 * prec * rec / (prec + rec)\n",
    "print('F1 Score: {:.4f}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Classifier using pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(MLP, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features, 512)  # Input layer\n",
    "        self.fc2 = nn.Linear(512, 256)  # Hidden layer\n",
    "        self.fc3 = nn.Linear(256, 128)  # Hidden layer\n",
    "        self.fc4 = nn.Linear(128, 64)  # Hidden layer\n",
    "        self.fc5 = nn.Linear(64, out_features)   # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch 1/20\n",
      "----------\n",
      "epoch train loss: 0.0254 Acc: 80.6186\n",
      "Epoch 2/20\n",
      "----------\n",
      "epoch train loss: 0.0186 Acc: 86.5378\n",
      "Epoch 3/20\n",
      "----------\n",
      "epoch train loss: 0.0147 Acc: 89.9313\n",
      "Epoch 4/20\n",
      "----------\n",
      "epoch train loss: 0.0125 Acc: 91.3660\n",
      "Epoch 5/20\n",
      "----------\n",
      "epoch train loss: 0.0112 Acc: 92.2337\n",
      "Epoch 6/20\n",
      "----------\n",
      "epoch train loss: 0.0103 Acc: 93.2818\n",
      "Epoch 7/20\n",
      "----------\n",
      "epoch train loss: 0.0088 Acc: 94.4244\n",
      "Epoch 8/20\n",
      "----------\n",
      "epoch train loss: 0.0080 Acc: 95.0172\n",
      "Epoch 9/20\n",
      "----------\n",
      "epoch train loss: 0.0070 Acc: 95.6014\n",
      "Epoch 10/20\n",
      "----------\n",
      "epoch train loss: 0.0068 Acc: 95.7990\n",
      "Epoch 11/20\n",
      "----------\n",
      "epoch train loss: 0.0062 Acc: 96.3574\n",
      "Epoch 12/20\n",
      "----------\n",
      "epoch train loss: 0.0054 Acc: 96.6151\n",
      "Epoch 13/20\n",
      "----------\n",
      "epoch train loss: 0.0055 Acc: 96.6151\n",
      "Epoch 14/20\n",
      "----------\n",
      "epoch train loss: 0.0048 Acc: 97.2509\n",
      "Epoch 15/20\n",
      "----------\n",
      "epoch train loss: 0.0045 Acc: 97.3110\n",
      "Epoch 16/20\n",
      "----------\n",
      "epoch train loss: 0.0045 Acc: 97.3969\n",
      "Epoch 17/20\n",
      "----------\n",
      "epoch train loss: 0.0040 Acc: 97.4828\n",
      "Epoch 18/20\n",
      "----------\n",
      "epoch train loss: 0.0037 Acc: 97.8265\n",
      "Epoch 19/20\n",
      "----------\n",
      "epoch train loss: 0.0039 Acc: 97.6890\n",
      "Epoch 20/20\n",
      "----------\n",
      "epoch train loss: 0.0033 Acc: 98.1186\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import optim\n",
    "\n",
    "# Convert dataframes to tensors\n",
    "X_train = torch.tensor(df_train.iloc[:, :-1].values, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "y_train = torch.tensor(df_train.iloc[:, -1].values, dtype=torch.long)\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# Create an instance of the model\n",
    "model = MLP(187, 2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "EPOCHS_NO = 20\n",
    "# Training loop\n",
    "best_model_wts = model.state_dict()\n",
    "best_acc = 0.0\n",
    "iteration = 0\n",
    "for epoch in range(EPOCHS_NO):  # Number of epochs\n",
    "    print('Epoch {}/{}'.format(epoch+1, EPOCHS_NO))\n",
    "    print('-'*10)\n",
    "    train_loss = 0.0\n",
    "    train_corrects = 0.0\n",
    "    model = model.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iter_loss = loss.item()\n",
    "        train_loss += iter_loss\n",
    "        iter_corrects = torch.sum(preds == labels.data).to(torch.float32)\n",
    "        train_corrects += iter_corrects\n",
    "        iteration += 1\n",
    "    epoch_loss = train_loss / len(train_dataset)\n",
    "    epoch_acc = train_corrects / len(train_dataset)\n",
    "    epoch_acc = epoch_acc * 100\n",
    "\n",
    "    if epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model_wts = model.state_dict()\n",
    "\n",
    "    print('epoch train loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "\n",
    "# Assuming that `model` is your model\n",
    "model.load_state_dict(best_model_wts)\n",
    "\n",
    "# Convert dataframes to tensors\n",
    "X_test = torch.tensor(df_test.iloc[:, :-1].values, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "y_test = torch.tensor(df_test.iloc[:, -1].values, dtype=torch.long)\n",
    "\n",
    "# Create dataloaders\n",
    "test_dataset = TensorDataset(X_train, y_train)\n",
    "test_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Then you can evaluate the model\n",
    "model.eval()\n",
    "\n",
    "test_dataset_size = len(test_dataset)\n",
    "true_positive_avg = 0\n",
    "true_negative_avg = 0\n",
    "false_positive_avg = 0\n",
    "false_negative_avg = 0\n",
    "\n",
    "num_classes = len(torch.unique(y_test))\n",
    "true_positive = [0] * num_classes\n",
    "true_negative = [0] * num_classes\n",
    "false_positive = [0] * num_classes\n",
    "false_negative = [0] * num_classes\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        true_positive_avg += (predicted * labels).sum().item()\n",
    "        true_negative_avg += ((1 - predicted) * (1 - labels)).sum().item()\n",
    "        false_positive_avg += (predicted * (1 - labels)).sum().item()\n",
    "        false_negative_avg += ((1 - predicted) * labels).sum().item()\n",
    "\n",
    "        for i in range(num_classes):\n",
    "            true_positive[i] += ((predicted == i) & (labels == i)).sum().item()\n",
    "            true_negative[i] += ((predicted != i) & (labels != i)).sum().item()\n",
    "            false_positive[i] += ((predicted == i) & (labels != i)).sum().item()\n",
    "            false_negative[i] += ((predicted != i) & (labels == i)).sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.9848\n",
      "Precision: 0.9898\n",
      "Recall: 0.9892\n",
      "F1 Score: 0.9895\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "acc = (true_positive_avg + true_negative_avg) / test_dataset_size\n",
    "print('Test Acc: {:.4f}'.format(acc))\n",
    "\n",
    "# Precision\n",
    "prec = true_positive_avg / (true_positive_avg + false_positive_avg)\n",
    "print('Precision: {:.4f}'.format(prec))\n",
    "# Recall\n",
    "rec = true_positive_avg / (true_positive_avg + false_negative_avg)\n",
    "print('Recall: {:.4f}'.format(rec))\n",
    "# F1 Score\n",
    "f1 = 2 * prec * rec / (prec + rec)\n",
    "print('F1 Score: {:.4f}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 metrics:\n",
      "  Accuracy: 0.9848\n",
      "  Precision: 0.9719\n",
      "  Recall: 0.9734\n",
      "  F1 Score: 0.9727\n",
      "Class 1 metrics:\n",
      "  Accuracy: 0.9848\n",
      "  Precision: 0.9898\n",
      "  Recall: 0.9892\n",
      "  F1 Score: 0.9895\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for each class\n",
    "accuracy = [0] * num_classes\n",
    "precision = [0] * num_classes\n",
    "recall = [0] * num_classes\n",
    "f1_score = [0] * num_classes\n",
    "\n",
    "for i in range(num_classes):\n",
    "    accuracy[i] = (true_positive[i] + true_negative[i]) / (true_positive[i] + true_negative[i] + false_positive[i] + false_negative[i])\n",
    "    precision[i] = true_positive[i] / (true_positive[i] + false_positive[i]) if (true_positive[i] + false_positive[i]) != 0 else 0\n",
    "    recall[i] = true_positive[i] / (true_positive[i] + false_negative[i]) if (true_positive[i] + false_negative[i]) != 0 else 0\n",
    "    f1_score[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i]) if (precision[i] + recall[i]) != 0 else 0\n",
    "\n",
    "    # Print metrics\n",
    "for i in range(num_classes):\n",
    "    print(f\"Class {i} metrics:\")\n",
    "    print(f\"  Accuracy: {accuracy[i]:.4f}\")\n",
    "    print(f\"  Precision: {precision[i]:.4f}\")\n",
    "    print(f\"  Recall: {recall[i]:.4f}\")\n",
    "    print(f\"  F1 Score: {f1_score[i]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
