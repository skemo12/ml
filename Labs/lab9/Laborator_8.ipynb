{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cs-pub-ro/ML/blob/master/lab/lab8/Laborator_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tmaHAc_KHG_5"
   },
   "source": [
    "# Rețele neurale pentru clasificare imaginilor\n",
    "\n",
    "_Tudor Berariu, 2018_ (tudor.berariu@gmail.com)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xKCKTWvsuJuF"
   },
   "source": [
    "În cadrul acestui laborator veți implementa o rețea neurală pentru clasificarea imaginilor.\n",
    "Rețeaua va fi compusă din straturi lineare și activări de tip ReLU și un strat softmax înainte de ieșiri. Funcția de cost folosită va fi negative log likelihood. Pentru optimizarea acesteia se va folosi SGD (stochastic gradient descent)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zgNIWhzoHOIz"
   },
   "source": [
    "## 1. Setul de date MNIST\n",
    "\n",
    "Setul de date MNIST este compus din imagini de 28x28 pixeli reprezentând una dintre cele zece cifre 0-9.\n",
    "\n",
    "Decomentați mai jos comanda `!pip install mnist` pentru a instala pachetul `mnist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dQiqJyO7E7Ek"
   },
   "outputs": [],
   "source": [
    "# !pip install mnist\n",
    "# import mnist\n",
    "\n",
    "# !pip install tensorflow\n",
    "# from tensorflow.keras.datasets import mnist\n",
    "# train_imgs = mnist.train_images()\n",
    "# train_labels = mnist.train_labels()\n",
    "# test_imgs = mnist.test_images()\n",
    "# test_labels  = mnist.test_labels()\n",
    "# (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "import gzip\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "url = \"https://s3.amazonaws.com/img-datasets/mnist.pkl.gz\"\n",
    "filename = \"mnist.pkl.gz\"\n",
    "\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "\n",
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "if sys.version_info < (3,):\n",
    "    data = pickle.load(f)\n",
    "else:\n",
    "    data = pickle.load(f, encoding='bytes')\n",
    "f.close()\n",
    "(train_imgs, train_labels), (test_imgs, test_labels) = data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ElGfqnPzuJuO"
   },
   "source": [
    "### Exemple din setul de date MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qeftJ_CpE7Eu"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "avJh9wQquJuU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [1 7 5 7 6 2 6 7 2 2 1 8 7 1 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idxs = np.random.randint(0, len(train_imgs), 15)\n",
    "imgs = np.concatenate(tuple(train_imgs[idx,:,:] for idx in idxs), axis=1)\n",
    "plt.imshow(imgs)\n",
    "print(\"Labels:\", train_labels[idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KFP9QnUJuJuY"
   },
   "source": [
    "### Standardizarea datelor\n",
    "\n",
    "Datele de intrare (imaginile) vor fi rescalate pentru a avea media zero și deviația standard 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wWmt4XVxuJuZ"
   },
   "outputs": [],
   "source": [
    "mean, std  = train_imgs.mean(), train_imgs.std()\n",
    "train_imgs = (train_imgs - mean) / std\n",
    "test_imgs = (test_imgs - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZgERUA07IuSr"
   },
   "source": [
    "## 2. Construirea unei rețele de tip feed-forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BE-V6sONuJud"
   },
   "source": [
    "### Notații\n",
    "  - dimensiunea datelor de intrare este $D = 28 * 28 = 784$, iar dimensiunea ieșirilor rețelei este $K=10$ (numărul de clase)\n",
    "  - rețeaua neurală va avea $L$ straturi\n",
    "  - $B$ va reprezenta dimensiunea batch-ului (numărul de exemple trecute în același timp prin rețea)\n",
    "  - Vom nota cu ${\\bf X} \\in {\\mathbb R}^{B \\times D}$ un batch de intrări $\\left\\lbrace {\\bf x}_0, {\\bf x}_1, \\dots {\\bf x}_B \\right\\rbrace$ și similar ${\\bf Y} \\in {\\mathbb R}^{B \\times K}$\n",
    "  - ${\\bf x}^{(l)}$ reprezintă intrările stratului $l$ (${\\bf x}^{(0)}$ va fi o imagine precum cele din setul MNIST de dimensiune $D$)\n",
    "  - ${\\bf y}^{(l)}$ reprezintă ieșirile stratului $l$ (${\\bf y}^{(L-1)}$ reprezintă ieșirile rețelei)\n",
    "  - ${\\bf \\theta}^{(l)}$ reprezintă parametrii stratului $l$\n",
    "  - ${\\cal L}$ reprezintă funcția de cost ( _negative log likelihood_ )\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6YTu4tS8uJue"
   },
   "source": [
    "### Straturile rețelei\n",
    "\n",
    "Unele straturi au parametri ce trebuie optimizați în timpul antrenării. Vom nota parametrii stratului $l$ cu $\\bf{\\theta}^{(l)}$.\n",
    "Fiecare strat pe care îl veți implementa va avea trei metode:\n",
    " - `forward` calculează și întoarce ${\\bf y}^{(l)} = f_l\\left({\\bf x}^{(l)}, {\\bf \\theta}^{(l)}\\right)$\n",
    " - `backward` primește $\\frac{\\partial {\\cal L}}{\\partial {\\bf y}^{(l)}}$, reține intern $\\frac{\\partial {\\cal L}}{\\partial {\\bf \\theta}^{(l)}}$ și întoarce $\\frac{\\partial {\\cal L}}{\\partial {\\bf x}^{(l)}}$\n",
    " - `update` modifică parametrii locali ${\\bf \\theta}^{(l)}$ folosing gradientul stocat $\\frac{\\partial{\\cal L}}{\\partial{\\bf \\theta}^{(l)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SW206j3euJuf"
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self, x: np.ndarray, dy: np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def update(self, *args, **kwargs):\n",
    "        pass  # If a layer has no parameters, then this function does nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NIT6K4IduJuk"
   },
   "source": [
    "### Rețeaua neurală\n",
    "\n",
    "  * în faza `forward` ieșirile stratului $l$ devin intrările stratului $l+1$: ${\\bf x}^{(l+1)} = {\\bf y}^{(l)}$\n",
    "  * în faza `backward` gradientul în raport cu intrările stratului $l+1$ devine gradientul în raport cu ieșirile stratului $l$: $\\frac{\\partial {\\cal L}}{\\partial {\\bf y}^{(l)}}=\\frac{\\partial {\\cal L}}{\\partial {\\bf x}^{(l+1)}}$\n",
    "  \n",
    "**[Cerința 0]** Completați metoda `backward` din clasa `FeedForwardNetwork`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTn-g3KAuJul"
   },
   "outputs": [],
   "source": [
    "class FeedForwardNetwork:\n",
    "\n",
    "    def __init__(self, layers: List[Layer]):\n",
    "        self.layers = layers\n",
    "\n",
    "    def forward(self, x: np.ndarray, train: bool = True) -> np.ndarray:\n",
    "        self._inputs = []\n",
    "        for layer in self.layers:\n",
    "            if train:\n",
    "                self._inputs.append(x)\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, dy:np.ndarray) -> np.ndarray:\n",
    "        # TODO <0> : Compute the backward phase\n",
    "        for layer, x in zip(reversed(self.layers), reversed(self._inputs)):\n",
    "            dy = layer.backward(x, dy)\n",
    "        return dy\n",
    "\n",
    "    def update(self, *args, **kwargs):\n",
    "        for layer in self.layers:\n",
    "            layer.update(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VyQLVM4quJup"
   },
   "source": [
    "### Stratul linear\n",
    "\n",
    "Un strat linear cu $M$ intrări și $N$ ieșiri are parametrii $\\theta = \\left( {\\bf W}, {\\bf b} \\right)$ unde ${\\bf W} \\in \\mathbb{R}^{M \\times N}$ și ${\\bf b} \\in \\mathbb{R}^{N}$.\n",
    "\n",
    "Pentru un singur exemlu ${\\bf x} \\in {\\mathbb R}^{M}$:\n",
    "$$ {\\bf y} = {\\bf x}^{\\intercal}{\\bf W} + {\\bf b} $$\n",
    "\n",
    "**[Cerința 1]** Implementați metoda `forward` care primește un batch de exemple $X \\in {\\mathbb R}^{B\\times M}$ și întoarce ieșirile corespunzătoare: $Y \\in {\\mathbb R}^{B\\times N}$.\n",
    "\n",
    "**[Cerința 2]** Implementați metoda `backward` care primește un batch de exemple $X \\in {\\mathbb R}^{B\\times M}$ și gradientul în raport cu ieșirile $\\frac{\\partial {\\cal L}}{\\partial {\\bf Y}}$ și realizează două lucruri:\n",
    "  - calculează și salvează intern gradientul $\\frac{\\partial {\\cal L}}{\\partial {\\bf \\theta}}$\n",
    "  - calculează și întoarce gradientul $\\frac{\\partial {\\cal L}}{\\partial {\\bf X}}$\n",
    "  \n",
    "**[BONUS][Cerința 9]** Implementați strategia de optimizare SGD cu _momentum_ (în metoda `update`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S47ZsyKdE7FF"
   },
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "\n",
    "    def __init__(self, insize: int, outsize: int) -> None:\n",
    "        bound = np.sqrt(6. / insize)\n",
    "        self.weight = np.random.uniform(-bound, bound, (insize, outsize))\n",
    "        self.bias = np.zeros((outsize,))\n",
    "\n",
    "        self.dweight = np.zeros_like(self.weight)\n",
    "        self.dbias = np.zeros_like(self.bias)\n",
    "\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        # TODO <1> : compute the output of a linear layer\n",
    "        # x - is a B x M numpy array, where B - batchsize, M - size of input features (insize)\n",
    "        # Hint: use numpy matrix multiplication to implement the forward pass in one go\n",
    "        # for all the examples in the batch\n",
    "        return np.dot(x, self.weight) + self.bias\n",
    "\n",
    "\n",
    "    def backward(self, x: np.ndarray, dy: np.ndarray) -> np.ndarray:\n",
    "        # TODO <2> : compute dweight, dbias and  return dx\n",
    "        # x - is a B x M numpy array, where B - batchsize, M - size of input features (insize)\n",
    "        # dy - is a B x N numpy array, where B - batchsize, N - size of output features (outsize)\n",
    "        # Hint: use numpy matrix multiplication to implement the backward pass in one go\n",
    "        #       for self.dweight\n",
    "        # Hint: use numpy.sum to implement the backward pass in one go for self.dbias\n",
    "        self.dweight = np.dot(x.T, dy)\n",
    "        self.dbias = np.sum(dy, axis=0)\n",
    "        dx = np.dot(dy, self.weight.T)\n",
    "        return dx\n",
    "\n",
    "    def update(self, mode='SGD', lr=0.001, mu=0.9):\n",
    "        if mode == 'SGD':\n",
    "            self.weight -= lr * self.dweight\n",
    "            self.bias -= lr * self.dbias\n",
    "        elif mode == 'momentum':\n",
    "            # TODO <9>: implement momentum update\n",
    "            if not hasattr(self, 'velocity_weight'):\n",
    "                self.velocity_weight = np.zeros_like(self.weight)\n",
    "                self.velocity_bias = np.zeros_like(self.bias)\n",
    "\n",
    "            self.velocity_weight = mu * self.velocity_weight - lr * self.dweight\n",
    "            self.velocity_bias = mu * self.velocity_bias - lr * self.dbias\n",
    "\n",
    "            self.weight += self.velocity_weight\n",
    "            self.bias += self.velocity_bias\n",
    "        else:\n",
    "            raise ValueError('mode should be SGD or momentum, not ' + str(mode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QgfHlVgDuJut"
   },
   "source": [
    "### The Rectified Linear Unit\n",
    "\n",
    "Stratul ReLU aplică următoare următoare transformare neliniară element cu element:\n",
    "$$y = \\max\\left(x, 0\\right)$$\n",
    "\n",
    "**[Cerințele 3-4]** Implementați metodele `forward` și `backward` pentru un strat de activare ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QOR1DJiwE7FJ"
   },
   "outputs": [],
   "source": [
    "class ReLU(Layer):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        # TODO <3> : Compute the output of a rectified linear unit\n",
    "        return np.maximum(x, 0)\n",
    "\n",
    "    def backward(self, x: np.ndarray, dy: np.ndarray) -> np.ndarray:\n",
    "        # TODO <4> : Compute the gradient w.r.t. x\n",
    "        # x - is a B x M numpy array, where B - batchsize, M - size of features\n",
    "        # Hint: use numpy logical indexing to determine where the input (x) is negative\n",
    "        #       and make the gradient 0 for those examples\n",
    "        dx = dy.copy()\n",
    "        dx[x <= 0] = 0\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4NrWBTmbI9gW"
   },
   "source": [
    "## 3. Funcția de cost\n",
    "\n",
    "Funcția de cost pe care o vom folosi este _cross entropy_ care combină un _softmax_ și un cost _negative log-likelihood_. (Matematica la tablă)\n",
    "\n",
    "Dacă ${\\bf y}$ reprezintă ieșrile rețelei pentru o intrare ${\\bf x}$, atunci ${\\bf y}$ va avea o dimensiune egală cu numărul de clase $K$. Atunci probabilitatea (prezisă de rețea) ca exemplul ${\\bf x}$ să aparțină clasei $k$ va fi $p_k$:\n",
    "$$\\begin{align}\n",
    "p_k &= \\frac{e^{y_k}}{\\sum_j e^{y_j}} & & \\text{softmax} \\\\\n",
    "{\\cal L} &= -\\log p_t & & \\text{negative log-likelihood}\n",
    "\\end{align}$$\n",
    "\n",
    "\n",
    "Pentru un batch de dimensiune $B$ se va face media costurilor corespunzătare fiecărui exemplu ($p_k$ este o funcție de ${\\bf x}$ și ${\\bf \\theta}$):\n",
    "\n",
    "$$ {\\cal L} = \\frac{1}{B} \\sum_{({\\bf x}, {\\bf t}) \\in Batch} -\\log p_t \\left({\\bf x}, \\theta\\right) $$\n",
    "\n",
    "\n",
    "**[Cerințele 5-6]** Implementați metodele `forward` și `backward` pentru un funcția de cost _cross-entropy_ (o vom privi ca pe un strat suplimentar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YDXiDEu8E7FW"
   },
   "outputs": [],
   "source": [
    "class CrossEntropy:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def softmax(self, x):\n",
    "        exps = np.exp(x)\n",
    "        return exps / np.sum(exps,axis = 1).reshape(-1,1)\n",
    "\n",
    "    def forward(self, y: np.ndarray, t: np.ndarray) -> float:\n",
    "        # TODO <5> : Compute the negative log likelihood\n",
    "        # y - (B, K) numpy array, where B - batchsize, K - number of classes (number of logits)\n",
    "        # t - (B, ) numpy array, where B - batchsize, which indicates the correct class\n",
    "        m = y.shape[0]\n",
    "        p = self.softmax(y)\n",
    "        log_likelihood = -np.log(p[np.arange(m), t])\n",
    "        loss = np.sum(log_likelihood) / m\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "    def backward(self, y: np.ndarray, t: np.ndarray) -> np.ndarray:\n",
    "        # TODO <6> : Compute dl/dy\n",
    "        m = y.shape[0]\n",
    "        p = self.softmax(y)\n",
    "        p[np.arange(m), t] -= 1\n",
    "        p /= m\n",
    "        return p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uz9qM5eHJLNw"
   },
   "source": [
    "### Acuratețea\n",
    "\n",
    "**[Cerința 7]** Calculați acuratețea predicțiilor ${\\bf y}$ în raport cu clasele corecte ${\\bf t}$ (rația exemplelor pentru care clasa corectă a avut probabilitatea prezisă maximă)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nYfVCBSE7Fe"
   },
   "outputs": [],
   "source": [
    "def accuracy(y: np.ndarray, t: np.ndarray) -> float:\n",
    "    # TODO <7> : Compute accuracy\n",
    "    predictions = np.argmax(y, axis=1)\n",
    "    correct = np.sum(predictions == t)\n",
    "    accuracy = correct / y.shape[0]\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mIhtzd2gJQF2"
   },
   "source": [
    "## 4. Antrenarea rețelei neurale\n",
    "\n",
    "**[Cerința 8]** Completați codul de mai jos pentru a calcula gradientul funcției de cost pentru batchul ales și parametrii curenți ai rețelei. _Indiciu_: trebuie să apelați metodele `forward` și `backward` ale rețelei neurale și ale funcției de cost.\n",
    "\n",
    "**[BONUS]** Implementați optimizare cu _momentum_ (vezi TODO-ul numărul 9 din metoda `update`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HTbmZv3YE7Fs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Batch 013 | Train NLL:  1.925 | Train Acc:  39.06% "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Batch 468 | Train NLL:  0.427 | Train Acc:  89.58% | Test NLL:  0.402 | Test Acc: 88.44%\n",
      "Epoch 02 | Batch 468 | Train NLL:  0.352 | Train Acc:  91.67% | Test NLL:  0.321 | Test Acc: 90.68%\n",
      "Epoch 03 | Batch 468 | Train NLL:  0.321 | Train Acc:  93.75% | Test NLL:  0.284 | Test Acc: 91.60%\n",
      "Epoch 04 | Batch 468 | Train NLL:  0.302 | Train Acc:  93.75% | Test NLL:  0.260 | Test Acc: 92.47%\n",
      "Epoch 05 | Batch 468 | Train NLL:  0.288 | Train Acc:  95.83% | Test NLL:  0.242 | Test Acc: 93.11%\n",
      "Epoch 06 | Batch 468 | Train NLL:  0.276 | Train Acc:  96.88% | Test NLL:  0.228 | Test Acc: 93.49%\n",
      "Epoch 07 | Batch 468 | Train NLL:  0.266 | Train Acc:  96.88% | Test NLL:  0.217 | Test Acc: 93.82%\n",
      "Epoch 08 | Batch 468 | Train NLL:  0.257 | Train Acc:  96.88% | Test NLL:  0.207 | Test Acc: 94.01%\n",
      "Epoch 09 | Batch 468 | Train NLL:  0.249 | Train Acc:  96.88% | Test NLL:  0.198 | Test Acc: 94.33%\n",
      "Epoch 10 | Batch 468 | Train NLL:  0.243 | Train Acc:  96.88% | Test NLL:  0.191 | Test Acc: 94.58%\n",
      "Epoch 11 | Batch 468 | Train NLL:  0.237 | Train Acc:  96.88% | Test NLL:  0.184 | Test Acc: 94.80%\n",
      "Epoch 12 | Batch 468 | Train NLL:  0.232 | Train Acc:  96.88% | Test NLL:  0.178 | Test Acc: 94.93%\n",
      "Epoch 13 | Batch 468 | Train NLL:  0.227 | Train Acc:  96.88% | Test NLL:  0.172 | Test Acc: 95.02%\n",
      "Epoch 14 | Batch 468 | Train NLL:  0.223 | Train Acc:  97.92% | Test NLL:  0.167 | Test Acc: 95.12%\n",
      "Epoch 15 | Batch 468 | Train NLL:  0.219 | Train Acc:  97.92% | Test NLL:  0.162 | Test Acc: 95.20%\n",
      "Epoch 16 | Batch 468 | Train NLL:  0.216 | Train Acc:  97.92% | Test NLL:  0.158 | Test Acc: 95.32%\n",
      "Epoch 17 | Batch 468 | Train NLL:  0.213 | Train Acc:  97.92% | Test NLL:  0.154 | Test Acc: 95.43%\n",
      "Epoch 18 | Batch 468 | Train NLL:  0.210 | Train Acc:  97.92% | Test NLL:  0.150 | Test Acc: 95.60%\n",
      "Epoch 19 | Batch 468 | Train NLL:  0.208 | Train Acc:  97.92% | Test NLL:  0.147 | Test Acc: 95.73%\n",
      "Epoch 20 | Batch 468 | Train NLL:  0.205 | Train Acc:  97.92% | Test NLL:  0.144 | Test Acc: 95.85%\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "HIDDEN_UNITS = 300\n",
    "EPOCHS_NO = 20\n",
    "\n",
    "optimize_args = {'mode': 'SGD', 'lr': .005}\n",
    "\n",
    "net = FeedForwardNetwork([Linear(784, HIDDEN_UNITS),\n",
    "                          ReLU(),\n",
    "                          Linear(HIDDEN_UNITS, 10)])\n",
    "cost_function = CrossEntropy()\n",
    "\n",
    "for epoch in range(EPOCHS_NO):\n",
    "    for b_no, idx in enumerate(range(0, len(train_imgs), BATCH_SIZE)):\n",
    "        # 1. Prepare next batch\n",
    "        x = train_imgs[idx:idx + BATCH_SIZE,:,:].reshape(-1, 784)\n",
    "        t = train_labels[idx:idx + BATCH_SIZE]\n",
    "\n",
    "        # 2. Compute gradient\n",
    "\n",
    "        # TODO <8> : Compute gradient\n",
    "        y = net.forward(x)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = cost_function.forward(y, t)\n",
    "\n",
    "        # Backward pass\n",
    "        dy = cost_function.backward(y, t)\n",
    "        net.backward(dy)\n",
    "\n",
    "        # 3. Update network parameters\n",
    "        net.update(**optimize_args)\n",
    "\n",
    "        print(f'\\rEpoch {epoch + 1:02d} '\n",
    "              f'| Batch {b_no:03d} '\n",
    "              f'| Train NLL: {loss:6.3f} '\n",
    "              f'| Train Acc: {accuracy(y, t) * 100:6.2f}% ', end='')\n",
    "\n",
    "    y = net.forward(test_imgs.reshape(-1, 784), train=False)\n",
    "    test_nll = cost_function.forward(y, test_labels)\n",
    "    print(f'| Test NLL: {test_nll:6.3f} '\n",
    "          f'| Test Acc: {accuracy(y, test_labels) * 100:3.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J7zGgHlduJvA"
   },
   "source": [
    "## Teste\n",
    "\n",
    "Executați ```test0() and test16() and test7()``` pentru a rula testele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YaLsPBfuJvB"
   },
   "outputs": [],
   "source": [
    "def test0():\n",
    "    fakex = [np.random.randn(128, n) for n in [20, 40, 30, 10]]\n",
    "\n",
    "    class DummyLayer:\n",
    "        def __init__(self, idx):\n",
    "            self.idx = idx\n",
    "\n",
    "        def forward(self, x):\n",
    "            return fakex[self.idx + 1]\n",
    "\n",
    "        def backward(self, x, dldy):\n",
    "            if not np.allclose(x, fakex[self.idx]):\n",
    "                raise Exception(\"Intrări greșite în backward\")\n",
    "            if not np.allclose(dldy, -fakex[self.idx+1]):\n",
    "                raise Exception(\"Intrări greșite în backward\")\n",
    "            return -x\n",
    "\n",
    "    try:\n",
    "        net = FeedForwardNetwork([DummyLayer(i) for i in range(3)])\n",
    "        net.forward(fakex[0])\n",
    "        net.backward(-fakex[-1])\n",
    "        print(\"Cerința 0 rezolvată corect!\")\n",
    "        return True\n",
    "    except NotImplementedError as e:\n",
    "        print(\"Cerința 0 nu a fost implementată!\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Cerința 0 are erori.\")\n",
    "\n",
    "    return False\n",
    "\n",
    "def test16():\n",
    "    __x = np.array([[-3.0731, -1.9081, -0.7283, -0.0757, -0.7577],\n",
    "                    [ 2.4041, -1.1506, -0.5924,  1.3016,  1.0882],\n",
    "                    [-0.5254,  0.3519, -0.9633, -2.7393, -0.9745]])\n",
    "    __w = np.array([[ 1.3214, -0.5886, -0.0351,  1.2084,  1.2661, -0.9979, -0.1172],\n",
    "                    [-0.4022,  0.1168,  0.9020, -2.0098, -0.5409, -0.3876, -0.1719],\n",
    "                    [-1.1125, -0.5556,  0.8843,  0.6995,  0.4929,  0.7523,  0.1832],\n",
    "                    [ 0.2267,  0.6757,  1.1286, -0.3218,  1.6934, -0.1782, -0.3467],\n",
    "                    [-0.6062,  0.4426,  0.5090,  0.4772, -0.5721,  0.8658, -0.5999]])\n",
    "    __b = np.array([ 0.3335,  0.5051, -0.1393,  1.2116,  1.7836, -0.6597,  0.3553])\n",
    "    __y = np.array([[-1.70746622, 2.10919555, -2.8676804, 0.48630531, -1.1288499, 1.95609904, 1.39083457],\n",
    "                    [4.26749994, 0.64592254, 0.23749513, 6.11524068, 6.73936681, -2.34822291, -0.94127596],\n",
    "                    [0.5391161, -0.89159687, -4.24288533, -0.38789499, -3.62798139, -1.35206921, 1.71422657]])\n",
    "\n",
    "    __dy = np.array([[ 1.5555, -0.8978, -0.2917, -0.3868, -0.8257, -0.3491, -0.8658],\n",
    "                     [ 1.1146,  1.4914,  0.9591, -0.2613,  0.5887,  0.4794,  0.8565],\n",
    "                     [-0.1552, -1.6319,  1.7642,  1.0503,  0.1035 , -0.7186, -0.9782]])\n",
    "    __dx = np.array([[ 1.53113221,  0.51455541, -2.588423,   -1.49460989, -0.98384103],\n",
    "                     [ 0.41215308,  0.46469672, -0.59552791,  3.04147235, -0.08763244],\n",
    "                     [ 2.92549149, -0.25707023,  2.70531668,  1.15769427,  0.67643021]])\n",
    "    __dw = np.array(\n",
    "        [[-2.01905511,  7.20190418,  2.2752849,   0.00865613,  3.89837344,  2.60289719, 5.23374791],\n",
    "         [-4.30512319, -0.57717827,  0.07387429,  1.40830543,  0.9345816,  -0.13835527, 0.3223155 ],\n",
    "         [-1.64365553,  1.34237165, -2.05517959, -0.57525343,  0.15290988,  0.66248035, 1.0654716 ],\n",
    "         [ 1.75815137,  6.47943337, -3.56222681, -3.18791411,  0.54523986,  2.61887489, 3.85994472],\n",
    "         [ 0.18554777,  3.89349109, -0.45449919, -1.01478565,  1.16539548,  1.48647185, 2.54131586]]\n",
    "    )\n",
    "    __db = np.array([ 2.5149, -1.0383,  2.4316,  0.4022, -0.1335, -0.5883, -0.9875])\n",
    "\n",
    "    __y_relu = np.array([[0, 2.10919555, 0, 0.48630531, 0, 1.95609904, 1.39083457],\n",
    "                         [4.26749994, 0.64592254, 0.23749513, 6.11524068, 6.73936681, 0, 0],\n",
    "                         [0.5391161, 0, 0, 0, 0, 0, 1.71422657]])\n",
    "    __drelu = np.array([[0, -0.8978, 0, -0.3868, 0, -0.3491, -0.8658],\n",
    "                        [ 1.1146,  1.4914,  0.9591, -0.2613,  0.5887,  0,  0],\n",
    "                        [-0.1552, 0,  0,  0,  0 , 0, -0.9782]])\n",
    "\n",
    "    __t = np.array([3, 1, 2])\n",
    "    __dl_dy = np.array(\n",
    "        [[ 2.80870645e-03,  1.27661957e-01,  8.80302096e-04, -3.08142112e-01,\n",
    "           5.00952130e-03,  1.09539948e-01,  6.22416775e-02],\n",
    "         [ 1.73238217e-02, -3.32870086e-01,  3.07917841e-04,  1.09927743e-01,\n",
    "           2.05192672e-01,  2.31991342e-05,  9.47329526e-05],\n",
    "         [ 6.60308812e-02,  1.57905168e-02, -3.32780047e-01,  2.61307149e-02,\n",
    "           1.02329216e-03,  9.96358772e-03,  2.13841054e-01]]\n",
    "    )\n",
    "\n",
    "\n",
    "    try:\n",
    "        lin = Linear(5, 7)\n",
    "        lin.weight = __w.copy()\n",
    "        lin.bias = __b.copy()\n",
    "        y = lin.forward(__x.copy())\n",
    "        if not np.allclose(y, __y):\n",
    "            raise Exception(\"Ieșiri greșite\")\n",
    "        print(\"Cerința 1 rezolvată corect!\")\n",
    "    except NotImplementedError as e:\n",
    "        print(\"Cerința 1 nu a fost implementată!\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Cerința 1 are erori.\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        dx = lin.backward(__x.copy(), __dy.copy())\n",
    "        if not np.allclose(dx, __dx):\n",
    "            raise ValueError(\"dL/dx greșit\")\n",
    "        if not np.allclose(lin.dweight, __dw):\n",
    "            raise ValueError(\"dL/dw greșit\")\n",
    "        if not np.allclose(lin.dbias, __db):\n",
    "            raise ValueError(\"dL/db greșit\")\n",
    "        print(\"Cerința 2 rezolvată corect!\")\n",
    "    except NotImplementedError as e:\n",
    "        print(\"Cerința 2 nu a fost implementată!\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Cerința 2 are erori.\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        relu = ReLU()\n",
    "        y_relu = relu.forward(__y.copy())\n",
    "        if not np.allclose(y_relu, __y_relu):\n",
    "            raise ValueError(\"ReLU(x) greșit\")\n",
    "        print(\"Cerința 3 rezolvată corect!\")\n",
    "    except NotImplementedError as e:\n",
    "        print(\"Cerința 3 nu a fost implementată!\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Cerința 3 are erori.\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        relu = ReLU()\n",
    "        drelu = relu.backward(__y.copy(), __dy.copy())\n",
    "        if not np.allclose(drelu, __drelu):\n",
    "            raise ValueError(\"ReLU.backward greșit\")\n",
    "        print(\"Cerința 4 rezolvată corect!\")\n",
    "    except NotImplementedError as e:\n",
    "        print(\"Cerința 4 nu a fost implementată!\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Cerința 4 are erori.\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        ce = CrossEntropy()\n",
    "        loss = ce.forward(__y.copy(), __t.copy())\n",
    "        if np.abs(loss - 5.1874357237332545) > 1e-6:\n",
    "            raise ValueError(f\"Valoare greșită nll: {loss:f} în loc de 5.1874357237332545\")\n",
    "        print(\"Cerința 5 rezolvată corect!\")\n",
    "    except NotImplementedError as e:\n",
    "        print(\"Cerința 5 nu a fost implementată!\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Cerința 5 are erori.\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        ce = CrossEntropy()\n",
    "        dl_dy = ce.backward(__y.copy(), __t.copy())\n",
    "        if not np.allclose(dl_dy, __dl_dy) > 1e-6:\n",
    "            raise ValueError(f\"Valoare greșită pentru dNLL/dy\")\n",
    "        print(\"Cerința 6 rezolvată corect!\")\n",
    "    except NotImplementedError as e:\n",
    "        print(\"Cerința 6 nu a fost implementată!\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Cerința 6 are erori.\")\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def test7():  # Acuratețea\n",
    "    y = np.array([[ 0.6460014 , -0.05876393, -1.36496105, -0.07057596,  0.54938383],\n",
    "                  [-0.8033942 , -0.51753041,  0.92278036, -1.66303585, -0.36537512],\n",
    "                  [-1.3710599 ,  0.65598193, -0.75527154,  1.21609284,  0.08284123],\n",
    "                  [-1.24696857,  0.32676634,  0.09572539,  1.38316398, -0.14110726],\n",
    "                  [-2.01698315,  2.06123375, -1.68003675,  0.0504592 ,  0.04427597],\n",
    "                  [-0.8893451 ,  1.74695148, -0.29394473,  0.74203068, -0.75185261],\n",
    "                  [ 1.34126333, -0.5272606 ,  1.46458319,  1.59529987,  1.86884676],\n",
    "                  [-0.58987297,  1.10900165, -0.71208103,  0.20478154, -1.26693567],\n",
    "                  [-2.17730677, -1.36147532, -1.49679182,  0.24812177, -0.13368035],\n",
    "                  [-0.48730599,  1.31710647,  0.41765538,  1.19869192, -0.05301611],\n",
    "                  [-0.10655224, -0.21174034,  1.31548647, -0.57990281,  0.85868472],\n",
    "                  [-0.32055613, -2.17817118, -0.28488692,  1.62977524,  0.25150929],\n",
    "                  [ 0.07704727,  1.67710047,  1.83368441, -0.45456845, -0.74474969]])\n",
    "    t = np.array([0, 2, 3, 3, 1, 0, 1, 1, 2, 1, 2, 3, 2])\n",
    "    try:\n",
    "        acc = accuracy(y, t)\n",
    "        if np.abs(acc - 0.7692307692307693) > 1e-7:\n",
    "            raise ValueError(f\"{acc:f} != 10/13\")\n",
    "        print(f\"Cerința 7 rezolvată corect!\")\n",
    "    except NotImplementedError as e:\n",
    "        print(\"Cerința 7 nu a fost implementată!\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Cerința 7 are erori.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nWQ2e7C4uJvD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cerința 0 rezolvată corect!\n",
      "Cerința 1 rezolvată corect!\n",
      "Cerința 2 rezolvată corect!\n",
      "Cerința 3 rezolvată corect!\n",
      "Cerința 4 rezolvată corect!\n",
      "Cerința 5 rezolvată corect!\n",
      "Cerința 6 rezolvată corect!\n",
      "Cerința 7 rezolvată corect!\n"
     ]
    }
   ],
   "source": [
    "test0() and test16() and test7()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Laborator 8",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
